\documentclass{beamer}
\usepackage{graphicx}
\usepackage{sourcecodepro}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{tikz-qtree}

\lstset{basicstyle=\ttfamily,breaklines=true}
\usepackage{upquote}
%\def\backtick{\char18}
\lstdefinestyle{backtickstyle}{literate={`}{\char}1, escapechar=@}

\usepackage{xcolor}
\usepackage{ulem}
\makeatletter
\def\uwave{\bgroup \markoverwith{\lower3.5\p@\hbox{\sixly \textcolor{red}{\char58}}}\ULon}
\font\sixly=lasy6 % does not re-load if already loaded, so no memory problem.
\makeatother
\lstdefinelanguage{Kotlin}{
comment=[l]{//},
commentstyle={\color{gray}\ttfamily},
%emph={delegate, filter, first, firstOrNull, forEach, map, mapNotNull, println, return@},
emphstyle={\color{red}},
identifierstyle=\color{black},
keywords={abstract, actual, as, as?, break, by, class, companion, continue, data, do, dynamic, else, enum, expect, false, final, for, fun, get, if, import, in, infix, interface, internal, is, null, object, open, operator, override, package, private, public, return, sealed, set, super, suspend, this, throw, true, try, typealias, val, var, vararg, when, where, while},
keywordstyle={\color{blue}\bfseries},
morecomment=[s]{/*}{*/},
morestring=[b]",
morestring=[s]{"""*}{*"""},
ndkeywords={@Deprecated, @JvmField, @JvmName, @JvmOverloads, @JvmStatic, @JvmSynthetic, Array, Byte, Double, DoublePrecision, Float, Int, Integer, Iterable, Long, Number, Runnable, Short, String},
ndkeywordstyle={\color{Orange}\bfseries},
sensitive=true,
stringstyle={\color{green}\ttfamily},
showstringspaces=false,
escapeinside={(*}{*)},
}

% Comparison Table
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{float}
\newcommand{\wmark}{\textcolor{orange}{\ding{45}}}
\newcommand{\cmark}{\textcolor{green!80!black}{\ding{51}}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\mediumwell}[1]{\textcolor{green}{#1}}
\newcommand{\medium}[1]{\textcolor{yellow}{#1}}
\newcommand{\mediumrare}[1]{\textcolor{orange}{#1}}
\newcommand{\rare}[1]{\textcolor{red}{#1}}

\mode<presentation> { \usetheme{Madrid} }

\title{Kotlin\texorpdfstring{$\nabla$}{}}
\subtitle{A Shape Safe eDSL for Differentiable Functional Programming}
\author{Breandan Considine}
\institute[McGill]{
McGill University \\
\medskip
\textit{breandan.considine@mcgill.ca}
}
\date{\today}

\begin{document}
    \begin{frame}
        \titlepage
    \end{frame}

    \begin{frame}
        \frametitle{Overview}
        \tableofcontents
    \end{frame}

    \section{A Short Lesson on Computing Derivatives}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Differentiation}
        If we have a function, $P(x): \mathbb{R}\rightarrow\mathbb{R}$, recall the derivative is defined as:
        %
        \begin{equation}
            P'(x) = \lim _{h\to 0}{\frac {f(x+h)-f(x)}{h}} = \frac{\Delta y}{\Delta x} = \frac{dP}{dx}
        \end{equation}
        %
        For $P(x_1, \dots, x_n): \mathbb{R}^n\rightarrow\mathbb{R}$, the gradient is a vector of derivatives:
        %
        \begin{equation}
            \nabla P = \left[\frac{\partial P}{\partial x_1}, \dots, \dfrac{\partial P}{\partial x_n}\right]\text{ where }\frac{\partial P}{\partial x_i} = \frac{dP}{dx_i}
        \end{equation}
        %
        For $\mathbf{P}(\mathbf{x}): \mathbb{R}^n\rightarrow\mathbb{R}^m$, the Jacobian is a vector of gradients:
        %
        \begin{equation}
            \mathcal{J}_\mathbf{P} = \left[\nabla P_1, \dots, \nabla P_n \right] \text{ or equivalently, } \mathcal{J}_{ij} = \frac{\partial P_i}{\partial x_j}
        \end{equation}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \section{Introduction and motivation}

    \begin{frame}
        \frametitle{Automatic differentiation}
        Suppose we have a scalar function $P_k: \mathbb{R}\rightarrow\mathbb{R}$ such that:
        %
        \begin{align*}
            P_k(x) = \begin{cases} p_1(x) = x &\text{if } k=1\\ (p_k\circ P_{k-1})(x)&\text{if } k > 1 \end{cases}
        \end{align*}
        %
        From the chain rule of calculus, we know that:
        %
        \begin{align*}
            \frac{dP}{dp_1} = \frac{dp_k}{dp_{k-1}}\frac{dp_{k-1}}{dp_{k-2}}\dots\frac{dp_2}{dp_1}= {\displaystyle \prod_{i=1}^{k} \frac{dp_{i+1}}{dp_{i}}}
        \end{align*}
        %
        For a vector function $\mathbf{P}_k(\mathbf{x}): \mathbb{R}^n\rightarrow\mathbb{R}^m$, the chain rule still applies:
        %
        \begin{align*}
            \mathcal{J}_\mathbf{P_k} = \displaystyle \prod_{i=1}^{k} \mathcal{J}_{p_i} = \underbrace{\bigg(\Big((\mathcal{J}_{p_k} \mathcal{J}_{p_{k-1}}) \dots \mathcal{J}_{p_2}\Big) \mathcal{J}_{p_1}\bigg)}_{\textit{``Reverse accumulation''}} = \underbrace{\bigg(\mathcal{J}_{p_k} \Big(\mathcal{J}_{p_{k-1}} \dots (\mathcal{J}_{p_2} \mathcal{J}_{p_1})\Big)\bigg)}_{\textit{``Forward accumulation''}}
        \end{align*}
        %
        If $\mathbf{P}_{k}$ were a program, what would the type signature of $\mathbf{p}_{0<i<k}$ be?
        %
        \begin{align*}
            \mathbf{p}_i: \mathcal{T}_{out}(\mathbf{p}_{i-1}) \rightarrow \mathcal{T}_{in}(\mathbf{p}_{i+1})
        \end{align*}
        %
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Parameter learning and gradient descent}
        For parametric models, let us rewrite $\mathbf{P}_k(\mathbf{x})$ as:
        %
        \begin{align*}
            \mathbf{\hat P}_k(\mathbf{x}; \mathbf{\boldsymbol\Theta}) = \begin{cases} \mathbf{p}_1(\boldsymbol\theta_1)(\mathbf{x}) &\text{if } k=1\\ \big(\mathbf{p}_k(\boldsymbol\theta_k)\circ \mathbf{\hat P}_{k-1}(\boldsymbol\Theta_{[1, k-1]})\big)\big(\mathbf{x}\big)&\text{if } k > 1 \end{cases} \\
        \end{align*}
        %
        Where $\boldsymbol\Theta = \{\boldsymbol\theta_1, \dots, \boldsymbol\theta_k\}$ are free parameters and $\mathbf{x} \in \mathbb{R}^n$ is a single input. Given $\mathbf{Y} = \{\mathbf{y}^{(1)} = \mathbf{P}(\mathbf{x}^{(1)}), \dots, \mathbf{y}^{(z)} = \mathbf{P}(\mathbf{x}^{(z)})\}$ from an oracle, in order to approximate $\mathbf{P}(\mathbf x)$, repeat the following procedure until $\boldsymbol\Theta$ converges:
        %
        \begin{align*}
            \boldsymbol\Theta \leftarrow \boldsymbol\Theta - \frac{1}{z}\nabla_{\boldsymbol\Theta} \sum_{i=0}^z\mathcal{L}\big(\mathbf{\hat P}_k(\mathbf{x}^{(i)}), \mathbf{y}^{(i)}\big)
        \end{align*}
        %
        If $\mathbf{\hat P}_{k}$ were a program, what would the type signature of $\mathbf{p}_{1<i<k}$ be?
        %
        \begin{align*}
            \mathbf{p}_i: \mathcal{T}_{out}(\mathbf{p}_{i-1}) \times \mathcal{T}(\boldsymbol\theta_{i}) \rightarrow \mathcal{T}_{in}\big(\mathbf{p}_{i+1}(\boldsymbol\theta_{i+1})\big)
        \end{align*}
        %
    \end{frame}
    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{What is differentiable programming?}
        \begin{center}
            \includegraphics[scale=0.07]{../figures/diff_prob_prog.png}
        \end{center}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Shape checking and inference}
        \begin{itemize}
            \item Scalar functions implicitly represent shape as arity $f(\cdot, \cdot): \mathbb{R}^2 \rightarrow \mathbb{R}$
            \item To check array programs, we need a type-level encoding of shape
            \item Arbitrary ops (e.g.\ convolution, vectorization) require dependent types
            \item But parametric polymorphism will suffice for many tensor functions
            \item For most algebraic operations, we just need to check for equality\ldots
        \end{itemize}
        {\scriptsize
            \begin{table}
            \begin{tabular}{|c|c|c|c|l|}\hline\multicolumn{1}{|c|}
            {\textbf{Math}}             & \textbf{Derivative}                    & \textbf{Code}                                                                                  &  \textbf{Type Signature}                                                                                                                                                                                    \\ \hline
                $a(b)$                  & $\mathcal{J}_a\mathcal{J}_b$             & \texttt{a(b)}                                                                                  &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{\pi}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{\tau})   \rightarrow (\mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{\pi})$                \\ \hline
                $a + b$                 & $\mathcal{J}_a + \mathcal{J}_b$          & \begin{tabular}{@{}c@{}}\texttt{a + b}\\\texttt{a.plus(b)}\\\texttt{plus(a, b)}\end{tabular}   &  $ (\texttt{a}:  \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{\pi}, \texttt{b}: \mathbb{R}^{\lambda} \rightarrow \mathbb{R}^{\pi}) \rightarrow (\mathbb{R}^{?}\rightarrow \mathbb{R}^{\pi})$                     \\ \hline
                $a   b$                 & $\mathcal{J}_a b + \mathcal{J}_b a$      & \begin{tabular}{@{}c@{}}\texttt{a * b}\\\texttt{a.times(b)}\\\texttt{times(a, b)}\end{tabular} &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{m \times n}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{n \times p})    \rightarrow (\mathbb{R}^{?}\rightarrow\mathbb{R}^{m \times p})$ \\ \hline
                $a ^ b$                 & \tiny{$a^b(a'\frac{b}{a} + b'\ln a)$}  & \begin{tabular}{@{}c@{}}\texttt{a.pow(b)}\\\texttt{pow(a, b)}\end{tabular}                     &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}) \rightarrow (\mathbb{R}^{?}\rightarrow\mathbb{R}) $                                          \\ \hline
            \end{tabular}
            \end{table}
        }
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Numerical tower}
        \begin{itemize}
            \item Abstract algebra can be useful when generalizing to new structures
            \item Helps us to easily translate between mathematics and source code
            \item Fields are a useful concept when computing over real numbers
            \begin{itemize}
                \item A field is a set $\mathbb{F}$ with two operations $+$ and $\times$, with the properties:
                \begin{itemize}
                    \item Associativity: $\forall a, b, c \in \mathbb{F}, a + (b + c) = (a + b) + c$
                    \item Commutivity: $\forall a, b \in \mathbb{F}, a + b = b + a$ and $a\times b = b\times a$
                    \item Distributivity: $\forall a, b, c \in \mathbb{F}, a \times (b \times c) = (a \times b) \times c$
                    \item Identity: $\forall a \in \mathbb{F}, \exists 0$, $ 1 \in F$ s.t. $a + 0 = a$ and $a\times 1= a$
                    \item $+$ inverse: $\forall a\in \mathbb{F}, \exists (-a)$ s.t. $a + (-a) = 0$
                    \item $\times$ inverse: $\forall a\neq 0 \in \mathbb{F}, \exists (a^{-1})$ s.t. $a \times a^{-1} = 1$
                \end{itemize}
            \end{itemize}
            \item Extensible to other number systems (e.g.\ complex, dual numbers)
            \item What is a program, but a series of arithmetic operations?
        \end{itemize}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Why Kotlin?}
        \begin{itemize}
            \item Goal: To implement automatic differentiation in Kotlin
            \item Kotlin is a language with strong static typing and null safety
            \item Supports first-class functions, higher order functions and lambdas
            \item Has support for algebraic data types through sealed classes
            \item Extension functions, operator overloading \& other syntax sugar
            \item Offers features for embedding domain specific languages (DSLs)
            \item Access to all libraries and frameworks in the JVM ecosystem
            \item Multi-platform and cross-platform (JVM, Android, iOS, JS, native)
        \end{itemize}
        \begin{center}
            \includegraphics[scale=0.05]{../figures/kotlin.png}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Kotlin\texorpdfstring{$\nabla$}{} Priorities}
        \begin{itemize}
            \item Type system
            \begin{itemize}
                \item Strong type system based on algebraic principles
                \item Leverage the compiler for static analysis
                \item No implicit broadcasting or shape coercion
                \item Parameterized numerical types and arbitary-precision
            \end{itemize}
            \item Design principles
            \begin{itemize}
                \item Functional programming and lazy numerical evaluation
                \item Eager algebraic simplification of expression trees
                \item Operator overloading and tapeless reverse mode AD
            \end{itemize}
            \item Usage desiderata
            \begin{itemize}
                \item Generalized AD with functional array programming
                \item Automatic differentiation with infix and Polish notation
                \item Partials and higher order derivatives and gradients
            \end{itemize}
            \item Testing and validation
            \begin{itemize}
                \item Numerical gradient checking and property-based testing
                \item Performance benchmarks and thorough regression testing
            \end{itemize}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Feature Comparison Matrix}
            \begin{center}
            \begin{tabular}{lllllllll}
            \textbf{Framework} & \textbf{Language}  & SD     & AD     & FP     & TS     & SS     & DP     & MP     \\ \hline
            \href{https://github.com/breandan/kotlingrad}{Kotlin$\nabla$}                    & Kotlin  & \cmark & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark \\
            \href{http://diffsharp.github.io/DiffSharp/}{DiffSharp}                          & F\#     & \xmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark \\
            \href{https://github.com/fsprojects/fsharp-ai-tools}{TensorFlow.FSharp}          & F\#     & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
            \href{https://tongfei.me/nexus/}{Nexus}                                          & Scala   & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
            \href{https://feiwang3311.github.io/Lantern/}{Lantern}                           & Scala   & \xmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark \\
            \href{https://github.com/HuwCampbell/grenade}{Grenade}                           & Haskell & \xmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark \\
            \href{http://uniker9.github.io/JAutoDiff/}{JAutoDiff}                            & Java    & \cmark & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark \\
            \href{https://halide-lang.org}{Halide}                                           & C++     & \xmark & \cmark & \xmark & \cmark & \xmark & \cmark & \xmark \\
            \href{https://github.com/Functional-AutoDiff/STALINGRAD}{Stalin$\nabla$}         & Scheme  & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark \\
            \href{https://github.com/mila-iqia/myia}{Myia}                                   & Python  & \cmark & \cmark & \cmark & \xmark & \xmark & \cmark & \wmark \\
            \href{https://github.com/HIPS/autograd/}{Autograd}                               & Python  & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark \\
            \href{https://github.com/google/jax}{JAX}                                        & Python  & \xmark & \cmark & \cmark & \xmark & \xmark & \cmark & \wmark \\
        \end{tabular}
        \end{center}
        \footnotesize{SD: Symbolic Differentiation, AD: Automatic Differentiation, FP: Functional Program, TS: Type-Safe, SS: Shape Safe, DP: Differentiable Programming, MP: Multiplatform}
    \end{frame}

    \section{Usage}

    \begin{frame}[fragile]
        \frametitle{Usage}
            \squeezeup\begin{figure}[!htb]
                  \begin{center}
                  \begin{tabular}{c}
                  \begin{lstlisting}[language=Kotlin, gobble=22]
                      val z = sin(10 * (x * x + pow(y, 2))) / 10
                  \end{lstlisting}
                  \end{tabular}
                  \end{center}
                  \vspace{10}
                  \squeezeup\centering
                  \begin{tikzpicture}[grow=left]
                      \tikzset{level distance=45pt}\squeezeup\squeezeup
                      \Tree [.$\div$ [.\texttt{sin} [.$\times$ \texttt{10} [.$+$ [.$\times$ \texttt{x} \texttt{x} ] [.\texttt{pow} \texttt{y} \texttt{2} ] ] ] ] \texttt{10} ]
                  \end{tikzpicture}
                  \squeezeup\squeezeup\squeezeup\caption{Implicit DFG constructed by the above expression, \texttt{z}.}
    \end{figure}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Usage: Plotting higher derivatives of nested functions}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            // Use double-precision floating point numerics
            with(DoublePrecision) {
              val x = Var()
              val y = sin(sin(sin(x)))/x + x*sin(x) + cos(x) + x

              // Perform lazy symbolic differentiation
              val dy_dx = d(y) / d(x)
              val d2y_dx = d(dy_dx) / d(x)
              val d3y_dx = d(d2y_dx2) / d(x)
              val d4y_dx = d(d3y_dx3) / d(x)
              val d5y_dx = d(d4y_dx4) / d(x)

              plot(-9..9, dy_dx, dy2_dx, d3y_dx, d4y_dx, d5y_dx)
            }
        \end{lstlisting}
    \end{frame}

    \begin{frame}
        \frametitle{$y = \frac{\sin{\sin{\sin{x}}}}{x} + x \sin{x} + \cos{x} + x$, $\frac{dy}{dx}$, $\frac{d^{2}y}{dx^2}$, $\frac{d^{3}y}{dx^3}$, $\frac{d^{4}y}{dx^4}$, $\frac{d^{5}y}{dx^5}$}
        \begin{center}
            \includegraphics[scale=0.55]{../figures/plot.png}
        \end{center}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Usage: 3D plotting with mixed higher order partials}

        \begin{center}
            \begin{tabular}{c}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            with(DoublePrecision) {
                val x = Var()
                val y = Var()

                val z = sin(10 * (x * x + pow(y, 2))) / 10
                val dz_dx = d(z) / d(x)
                val d2f_dxdy = d(dz_dx) / d(y)
                val d3z_d2xdy = d(d(dz_dx) / d(y)) / d(x)

                plot3d(-1, 1, d3z_d2xdy)
            }
        \end{lstlisting}
            \end{tabular}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{$z = \sin(10(x^2 + y^2)) / 10$, $\frac{\partial^3 z}{\partial^2 x \partial y}$}
        \begin{center}
            \includegraphics[scale=0.4]{../figures/plot3d.png}
        \end{center}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Currying and Partial Application}
        \begin{center}
            \begin{tabular}{c}
                \begin{lstlisting}[language=Kotlin, gobble=20]
                    with(DoublePrecision) {
                        val q0 = X + Y * Z + Y + 0.0
                        val p0 = q(X to 1.0, Y to 2.0, Z to 3.0)
                        val p1 = q(X to 1.0, Y to 1.0)(Z to 1.0)
                        val p3 = q(Z to 1.0)(X to 1.0, Y to 1.0)
                        val p4 = q(Z to 1.0)(X to 1.0)(Y to 1.0)
                        val p5 = q(Z to 1.0)(X to 1.0) // Fn<Y>
                        val q1 = X + Z + 0.0
                        val p6 = q1(Y to 1.0) // Error
                    }
                \end{lstlisting}
            \end{tabular}
        \end{center}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Vector Shape Safety}
        \begin{center}
            \begin{tabular}{c}
                \begin{lstlisting}[language=Kotlin, gobble=20]
                    with(DoublePrecision) {        // Inferred type:
                        val a = Vec(1.0, 2.0)      // Vec<Double, 2>
                        val b = Vec(1.0, 2.0, 3.0) // Vec<Double, 3>
                        val c = b + b              // Vec<Double, 3>
                        val d = a + b              // Compile error
                        val e = b dot b            // Vec<Double, 1>
                        val f = b dot a            // Compile error
                    }
                \end{lstlisting}
            \end{tabular}
        \end{center}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Matrix Shape Safety}
        \begin{center}
            \begin{tabular}{c}
                \begin{lstlisting}[language=Kotlin, gobble=20, style=backtickstyle]
                    // Inferred type: Mat<Double, `1`, `4`>
                    val a = Mat(1.0, 2.0, 3.0, 4.0)
                    // Inferred type: Mat<Double, `4`, `1`>
                    val b = Mat(1.0)(2.0)(3.0)(4.0)
                    val c = a * b

                    // Does not compile, inner dimension mismatch
                    // a * a
                    // b * b
                \end{lstlisting}
            \end{tabular}
        \end{center}
    \end{frame}

    \section{Future exploration}

    \begin{frame}
        \frametitle{Further directions to explore}
        \begin{itemize}
            \item Theory Directions
            \begin{itemize}
                \item Generalization of types to higher order functions, vector spaces
                \item Dependent types via code generation to type-check convolution
                \item General programming operators and data structures
                \item Imperative define-by-run array programming syntax
                \item Program induction and synthesis, cf.
                \begin{itemize}
                    \item The Derivative of a Regular Type is its Type of One-Hole Contexts
                    \item The Differential Lambda Calculus (2003)
                \end{itemize}
                \item Asynchronous gradient descent (cf. HogWild, YellowFin, et al.)
            \end{itemize}
            \item Implementation Details
            \begin{itemize}
                \item Closer integration with Kotlin/Java standard library
                \item Encode additional structure, i.e. function arity into type system
                \item Vectorized optimizations for matrices with certain properties
                \item Configurable forward and backward AD modes based on dimension
                \item Automatic expression refactoring for numerical stability
                \item \href{https://discuss.kotlinlang.org/t/primitive-type-specialization/11022}{Primitive type specialization}, i.e. \texttt{FloatVector <: Vector<T>}?
            \end{itemize}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \begin{center}
            \Huge{Learn more at: \\~\\
            \url{http://kg.ndan.co}}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Special thanks}
        \begin{itemize}
            \begin{center}
                \huge{
                Liam Paull \\
                Michalis Famelis \\
                }
                \vspace{10}
                \begin{tabular}{ll}
                    \includegraphics[scale=0.1]{../figures/mais_logo.jpg} & \raisebox{\height}{{\fontfamily{courier}\selectfont\textbf{Symposium I.A. Montr\'eal}}}\\
                \end{tabular} \\
                \includegraphics[scale=0.1]{../figures/udem.png}
                \includegraphics[scale=0.4]{../figures/mila.png}
            \end{center}
        \end{itemize}
    \end{frame}
\end{document}

%------------------------------------------------------------------------------------------------

%    \begin{frame}
%        \frametitle{Symbolic differentiation}
%        \begin{itemize}
%            \item What about evaluating functions symbolically?
%            \item Computer algebra systems for manipulate symbolic formulas
%        \end{itemize}
%    \end{frame}

%------------------------------------------------------------------------------------------------

%    \begin{frame}
%        \frametitle{Automatic differentiation}
%        \begin{itemize}
%            \item Derivatives can be calculated automatically? (Wengert, 1964)
%            \item Code as an \textit{exact} symbolic representation of functions
%            \item To reason about code we need the ability to treat \textit{code as data}:
%            \begin{itemize}
%                \item Reflection and metaprogramming
%                \item Domain specific languages
%                \item First-class functions
%            \end{itemize}
%        \end{itemize}
%    \end{frame}

%------------------------------------------------------------------------------------------------

%    \begin{frame}
%        \frametitle{Differentiable [functional] programming}
%        \begin{itemize}
%            \item What is a program, but a series of arithmetic operations?
%            \item What are arithmetic operations but syntactic sugar for functions?
%            \item Functions can be composed of other functions or chained in sequence
%            \item High school calculus gives us rules for differentiating function chains
%            \item Pearlmutter \& Siskind teach us AD is possible just using FP (2016)
%            \item Wang, Rompf, et al. show us this is possible \textit{without a tape}! (2018)
%        \end{itemize}
%    \end{frame}

%------------------------------------------------------------------------------------------------

%    \begin{frame}
%        \frametitle{Differentiable programming with algebraic types}
%        \begin{itemize}
%            \item Combine the tools from mathematics and CS
%            \item Type safety
%            \item Static analysis
%            \item Allows us to preserve symmetries that are not obvious
%            \item There is an abstract algebra for tensor manipulations
%            \item Can be encoded using OOP and parametric polymorphism
%            \item \href{https://arxiv.org/pdf/1610.07690.pdf}{Operational Calculus for Differentiable Programming}
%        \end{itemize}
%    \end{frame}

%------------------------------------------------------------------------------------------------
